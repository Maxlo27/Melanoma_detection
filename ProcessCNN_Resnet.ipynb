{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import keras.backend as K\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import les directory\n",
    "DIR_TRAINING='/root/Eve_Projet_Melanome/images/benin_malin/train'\n",
    "DIR_TESTING='/root/Eve_Projet_Melanome/images/benin_malin/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['malin', 'benin']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pour batir notre dataset, nous allons utiliser les dictionnaires\n",
    "#les classes que l'on tente de predire\n",
    "CLASSES = os.listdir(DIR_TRAINING)\n",
    "CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training={classe:[ \"{}/{}/{}\".format(DIR_TRAINING, classe,fichier) for fichier in os.listdir(\"{}/{}\".format(DIR_TRAINING, classe))] for classe in CLASSES}\n",
    "#for classe in CLASSES ici on recupère les clés\n",
    "testing={classe:[ \"{}/{}/{}\".format(DIR_TESTING, classe,fichier) for fichier in os.listdir(\"{}/{}\".format(DIR_TESTING, classe))] for classe in CLASSES}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malin 2803 images\n",
      "benin 26034 images\n"
     ]
    }
   ],
   "source": [
    "for classe , images in training.items():\n",
    "  print(classe,len(images), \"images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malin 117 images\n",
      "benin 6508 images\n"
     ]
    }
   ],
   "source": [
    "for classess , imagess in testing.items():\n",
    "  print(classess,len(imagess), \"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateurImages(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, dataset,batch_size=8, image_shape=(480, 480) ):\n",
    "      self.classes= list(dataset.keys())\n",
    "      self.dataset=[(image, [1 if i==self.classes.index(classe) else 0 for i in range(len(self.classes))])\n",
    "      for image in dataset[classe]\n",
    "      for classe in self.classes]\n",
    "      self.batch_size=batch_size\n",
    "      self.image_shape=image_shape\n",
    "      random.shuffle(self.dataset)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "      random.shuffle(self.dataset)\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.dataset) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch= self.dataset[idx*self.batch_size : (idx+1)*self.batch_size]\n",
    "        X,y=[],[]\n",
    "        for paire in batch:\n",
    "          X.append(self.prepare_x(paire[0]))\n",
    "          y.append(np.asarray(paire[1]).astype(np.float32))\n",
    "          return np.asarray(X).astype(np.float32), np.asarray(y).astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "    #fonction qui travaille l'image(nom) et retourne une matrice normalisée\n",
    "    def prepare_x(self, x):\n",
    "      image= cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n",
    "      image= cv2.resize(image, [self.image_shape[1],self.image_shape[0]] )\n",
    "      image= np.asarray(image).astype(np.float32)/ 255.0\n",
    "      return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creer des instances des generateur\n",
    "generateur_training= GenerateurImages(training)\n",
    "generateur_testing= GenerateurImages(testing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creer model keras\n",
    "modelResnet=tf.keras.applications.ResNet50(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_shape=(480,480,1),\n",
    "    classes=len(CLASSES),\n",
    "    classifier_activation=\"softmax\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction pour calculer le f1- score\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du callback pour suivre le meilleur score\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    '/root/hassan_projet_melanome/hassan_Traitement_test/sauvegarder/modelEfficientNetV2B2.h5',\n",
    "    monitor='val_f1',\n",
    "    mode='max',\n",
    "    save_best_only=True,    \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Utilisation des poids d'échantillonnage pour le déséquilibre de classes\n",
    "class_weights = {0: 1, 1: 10}  # Adapter les poids selon le déséquilibre des classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiler et enrainer\n",
    "modelResnet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", get_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 14:09:49.958088: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6508/6508 [==============================] - ETA: 0s - loss: 1.8611 - accuracy: 0.4922 - get_f1: 0.4922"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 16:35:07.638361: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
      "6508/6508 [==============================] - 9281s 1s/step - loss: 1.8611 - accuracy: 0.4922 - get_f1: 0.4922 - val_loss: 316.2477 - val_accuracy: 0.5071 - val_get_f1: 0.5071\n",
      "Epoch 2/2\n",
      "6508/6508 [==============================] - ETA: 0s - loss: 1.7178 - accuracy: 0.5089 - get_f1: 0.5089WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
      "6508/6508 [==============================] - 9393s 1s/step - loss: 1.7178 - accuracy: 0.5089 - get_f1: 0.5089 - val_loss: 1.5306 - val_accuracy: 0.4892 - val_get_f1: 0.4892\n",
      "Modèle enregistré avec succès.\n"
     ]
    }
   ],
   "source": [
    "modelResnet.fit(\n",
    "    x=generateur_training,\n",
    "    epochs=2,\n",
    "    validation_data=generateur_testing,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    class_weight=class_weights  # Utiliser les poids d'échantillonnage pour le déséquilibre\n",
    ")\n",
    "\n",
    "# Définir le chemin du fichier de sauvegarde\n",
    "save_path = \"/root/Eve_Projet_Melanome/Modeles/modelResnet.h5\"\n",
    "\n",
    "# Enregistrer le modèle\n",
    "modelResnet.save(save_path)\n",
    "\n",
    "print(\"Modèle enregistré avec succès.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cv2_imshow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m pred1\u001b[39m=\u001b[39mmodelResnet\u001b[39m.\u001b[39mpredict(ts_exp1)\n\u001b[1;32m     23\u001b[0m pred2\u001b[39m=\u001b[39mmodelResnet\u001b[39m.\u001b[39mpredict(ts_exp1)\n\u001b[0;32m---> 24\u001b[0m cv2_imshow(image)\n\u001b[1;32m     25\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPrediction:\u001b[39m\u001b[39m\"\u001b[39m,pred[\u001b[39m0\u001b[39m])\n\u001b[1;32m     26\u001b[0m cv2_imshow(image1)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2_imshow' is not defined"
     ]
    }
   ],
   "source": [
    "# Partie 1 - Faites les predictions sur les images\n",
    "image= cv2.imread(\"/root/Eve_Projet_Melanome/images/Image de prediction/images.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "image1= cv2.imread(\"/root/Eve_Projet_Melanome/images/Image de prediction/Melanoma.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "image2= cv2.imread(\"/root/Eve_Projet_Melanome/images/Image de prediction/mole_high_he_fr.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "#redimensionnement de l'image\n",
    "#redimensionnement de l'image\n",
    "\n",
    "#redimensionnement de l'image\n",
    "ts_res=cv2.resize(image,(480,480))\n",
    "ts_res1=cv2.resize(image1,(480,480))\n",
    "ts_res2=cv2.resize(image2,(480,480))\n",
    "#Normalisation de l'image\n",
    "ts_norm=np.asarray(ts_res).astype(np.float32)/255.0\n",
    "ts_norm1=np.asarray(ts_res1).astype(np.float32)/255.0\n",
    "ts_norm2=np.asarray(ts_res2).astype(np.float32)/255.0\n",
    "#etendre la dimension de l'image\n",
    "ts_exp=np.expand_dims(ts_norm, axis=0)\n",
    "ts_exp1=np.expand_dims(ts_norm1, axis=0)\n",
    "ts_exp2=np.expand_dims(ts_norm1, axis=0)\n",
    "#prediction\n",
    "pred=modelResnet.predict(ts_exp)\n",
    "pred1=modelResnet.predict(ts_exp1)\n",
    "pred2=modelResnet.predict(ts_exp1)\n",
    "cv2_imshow(image)\n",
    "print(\"Prediction:\",pred[0])\n",
    "cv2_imshow(image1)\n",
    "print(\"Prediction:\",pred1[0])\n",
    "cv2_imshow(image2)\n",
    "print(\"Prediction:\",pred2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
